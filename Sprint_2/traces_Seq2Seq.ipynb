{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, TimeDistributed\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datetime import timedelta\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = '/Users/xuenichen/Desktop/Process_Mining_1-main/data'\n",
    "chosed_dataset = 'BPI_Challenge_2017'\n",
    "data = pd.read_csv(f'{data_path}/train_test_{chosed_dataset}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamps to pandas datetime\n",
    "data['time:timestamp'] = pd.to_datetime(data['time:timestamp'])\n",
    "data.sort_values(by=['case:concept:name', 'time:timestamp'], inplace=True)\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "activity_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on all unique activities, including 'A_Create Application'\n",
    "all_activities = data['concept:name'].unique().tolist() + ['A_Create Application']\n",
    "activity_encoder.fit(all_activities)\n",
    "\n",
    "# Encode all activities in the dataset\n",
    "data['activity_encoded'] = activity_encoder.transform(data['concept:name'])\n",
    "\n",
    "# Group by case and create sequences of activity codes\n",
    "sequences = data.groupby('case:concept:name')['activity_encoded'].apply(list)\n",
    "\n",
    "# Find the maximum sequence length for padding\n",
    "max_seq_length = max(len(s) for s in sequences) + 1  # Plus one for the start token\n",
    "\n",
    "# Pad sequences\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n",
    "\n",
    "# Create start tokens for each sequence\n",
    "start_activity_code = activity_encoder.transform(['A_Create Application'])[0]\n",
    "start_tokens = np.full((padded_sequences.shape[0], 1), start_activity_code)\n",
    "# Add start tokens to the beginning of each sequence\n",
    "padded_sequences = np.hstack((start_tokens, padded_sequences))\n",
    "\n",
    "# Prepare input (X) and target (Y) for the model\n",
    "X = padded_sequences[:, :-1]  # All but the last column\n",
    "Y = to_categorical(padded_sequences[:, 1:], num_classes=len(activity_encoder.classes_))  # One-hot encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and Training the Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 681ms/step - accuracy: 0.7621 - loss: 1.0986 - val_accuracy: 0.8957 - val_loss: 0.3403\n",
      "Epoch 2/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 720ms/step - accuracy: 0.9026 - loss: 0.3098 - val_accuracy: 0.9361 - val_loss: 0.2081\n",
      "Epoch 3/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 742ms/step - accuracy: 0.9436 - loss: 0.1877 - val_accuracy: 0.9600 - val_loss: 0.1353\n",
      "Epoch 4/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 744ms/step - accuracy: 0.9610 - loss: 0.1301 - val_accuracy: 0.9635 - val_loss: 0.1122\n",
      "Epoch 5/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 779ms/step - accuracy: 0.9637 - loss: 0.1103 - val_accuracy: 0.9652 - val_loss: 0.1018\n",
      "Epoch 6/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 770ms/step - accuracy: 0.9653 - loss: 0.1019 - val_accuracy: 0.9673 - val_loss: 0.0963\n",
      "Epoch 7/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 765ms/step - accuracy: 0.9669 - loss: 0.0968 - val_accuracy: 0.9674 - val_loss: 0.0937\n",
      "Epoch 8/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 742ms/step - accuracy: 0.9675 - loss: 0.0941 - val_accuracy: 0.9682 - val_loss: 0.0910\n",
      "Epoch 9/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 729ms/step - accuracy: 0.9685 - loss: 0.0906 - val_accuracy: 0.9685 - val_loss: 0.0889\n",
      "Epoch 10/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 743ms/step - accuracy: 0.9683 - loss: 0.0909 - val_accuracy: 0.9689 - val_loss: 0.0878\n"
     ]
    }
   ],
   "source": [
    "# Define the Seq2Seq model architecture\n",
    "def build_seq2seq(input_dim, seq_len, embedding_dim=64, lstm_dim=256):\n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=(seq_len,))\n",
    "    encoder_embedding = Embedding(input_dim=input_dim, output_dim=embedding_dim)(encoder_inputs)\n",
    "    encoder_outputs, state_h, state_c = LSTM(lstm_dim, return_state=True)(encoder_embedding)\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    # Decoder\n",
    "    decoder_inputs = Input(shape=(seq_len,))\n",
    "    decoder_embedding = Embedding(input_dim=input_dim, output_dim=embedding_dim)(decoder_inputs)\n",
    "    decoder_lstm = LSTM(lstm_dim, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "    decoder_dense = TimeDistributed(Dense(input_dim, activation='softmax'))\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    # Seq2Seq Model\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Instantiate and compile the model\n",
    "seq_len = X.shape[1]\n",
    "input_dim = len(activity_encoder.classes_)\n",
    "seq2seq_model = build_seq2seq(input_dim, seq_len)\n",
    "seq2seq_model.compile(optimizer=Adam(1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "history = seq2seq_model.fit(\n",
    "    [X_train, X_train], Y_train,\n",
    "    batch_size=64,\n",
    "    epochs=5,  \n",
    "    validation_data=([X_val, X_val], Y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a sequence of activities\n",
    "def generate_full_sequence(model, input_seq, activity_encoder, max_length):\n",
    "    start_token = activity_encoder.transform(['A_Create Application'])[0]\n",
    "    decoder_input = np.zeros((1, max_length))\n",
    "    decoder_input[0, 0] = start_token  # setting the start token\n",
    "\n",
    "    output_seq = []\n",
    "\n",
    "    for i in range(1, max_length):\n",
    "        current_pred_probs = model.predict(\n",
    "            [input_seq, decoder_input], verbose=0)\n",
    "        current_pred = np.argmax(current_pred_probs[0, i - 1, :], axis=-1)\n",
    "        output_seq.append(current_pred)\n",
    "        decoder_input[0, i] = current_pred\n",
    "\n",
    "    decoded_sequence = activity_encoder.inverse_transform(output_seq)\n",
    "    return decoded_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this cell runs for more than 1h but without any output. At first showing the ms/step but after 20min, VScode died. So I switch to this. need someone to run and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict sequences for each case\n",
    "predicted_sequences = {}\n",
    "case_ids = sequences.index.tolist()\n",
    "\n",
    "for i, case_id in enumerate(case_ids):\n",
    "    input_seq = X[i:i+1]  # Select the encoder input for the current case\n",
    "    predicted_sequence = generate_full_sequence(seq2seq_model, input_seq, activity_encoder, max_seq_length)\n",
    "    predicted_sequences[case_id] = predicted_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the predictions into a DataFrame\n",
    "predictions_df = pd.DataFrame()\n",
    "\n",
    "# Find the last known timestamp for each case to use as the initial timestamp for predictions\n",
    "last_timestamps = data.groupby('case:concept:name')['time:timestamp'].last()\n",
    "\n",
    "# Generate predictions and format them\n",
    "for case_id, predicted_seq in predicted_sequences.items():\n",
    "    initial_timestamp = last_timestamps[case_id]\n",
    "    # Generate timestamps for each predicted activity, spaced one hour apart\n",
    "    timestamps = [initial_timestamp + timedelta(hours=i) for i in range(len(predicted_seq))]\n",
    "    case_df = pd.DataFrame({\n",
    "        'case:concept:name': [case_id] * len(predicted_seq),\n",
    "        'concept:name': predicted_seq,\n",
    "        'time:timestamp': timestamps\n",
    "    })\n",
    "    predictions_df = predictions_df.append(case_df, ignore_index=True)\n",
    "\n",
    "# Save the formatted predictions to a CSV file\n",
    "predictions_csv_path = f'{data_path}/Seq2Seq_predictions_{chosed_dataset}.csv'\n",
    "predictions_df.to_csv(predictions_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
