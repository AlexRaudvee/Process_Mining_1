{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Dense, Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from pm4py.objects.conversion.log import converter as log_converter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = '/Users/xuenichen/Desktop/Process_Mining_1-main/data'\n",
    "chosed_dataset = 'BPI_Challenge_2017'\n",
    "dataframe = pd.read_csv(f'{data_path}/train_test_{chosed_dataset}.csv')\n",
    "dataframe['time:timestamp'] = pd.to_datetime(dataframe['time:timestamp'])\n",
    "\n",
    "# Calculate average duration between events\n",
    "dataframe = dataframe.sort_values(['case:concept:name', 'time:timestamp'])\n",
    "\n",
    "dataframe['next_timestamp'] = dataframe.groupby('case:concept:name')['time:timestamp'].shift(-1)\n",
    "\n",
    "dataframe['duration'] = (dataframe['next_timestamp'] -dataframe['time:timestamp']).dt.total_seconds() / 60.0\n",
    "\n",
    "average_duration = dataframe['duration'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess and Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the CSV file into an event log\n",
    "parameters = {\n",
    "    \"case_id_glue\": \"case:concept:name\",\n",
    "    \"activity_key\": \"concept:name\",\n",
    "    \"timestamp_key\": \"time:timestamp\"\n",
    "}\n",
    "event_log = log_converter.apply(\n",
    "    dataframe, parameters=parameters, variant=log_converter.Variants.TO_EVENT_LOG)\n",
    "\n",
    "# Encode activities\n",
    "activity_encoder = LabelEncoder()\n",
    "all_activities = [event['concept:name']for trace in event_log for event in trace]\n",
    "\n",
    "activity_encoder.fit(all_activities)\n",
    "\n",
    "# Encode all activities in the log\n",
    "for trace in event_log:\n",
    "    for event in trace:\n",
    "        event['concept:name'] = activity_encoder.transform([event['concept:name']])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Train the Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_seq2seq_model(input_vocab_size, output_vocab_size, latent_dim=256):\n",
    "    # Define an input sequence and process it.\n",
    "    encoder_inputs = Input(shape=(None,))\n",
    "    encoder_embedding = Embedding(input_vocab_size, latent_dim)(encoder_inputs)\n",
    "    encoder_outputs, state_h, state_c = LSTM(latent_dim, return_state=True)(encoder_embedding)\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    # Set up the decoder, using `encoder_states` as initial state.\n",
    "    decoder_inputs = Input(shape=(None,))\n",
    "    decoder_embedding = Embedding(\n",
    "        output_vocab_size, latent_dim)(decoder_inputs)\n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(\n",
    "        decoder_embedding, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    # Define the model\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 746ms/step - accuracy: 0.9090 - loss: 0.3562 - val_accuracy: 0.9727 - val_loss: 0.0797\n",
      "Epoch 2/10\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 765ms/step - accuracy: 0.9736 - loss: 0.0762 - val_accuracy: 0.9739 - val_loss: 0.0738\n",
      "Epoch 3/10\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 789ms/step - accuracy: 0.9742 - loss: 0.0720 - val_accuracy: 0.9741 - val_loss: 0.0718\n",
      "Epoch 4/10\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 802ms/step - accuracy: 0.9746 - loss: 0.0697 - val_accuracy: 0.9767 - val_loss: 0.0613\n",
      "Epoch 5/10\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 760ms/step - accuracy: 0.9783 - loss: 0.0577 - val_accuracy: 0.9798 - val_loss: 0.0526\n",
      "Epoch 6/10\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 782ms/step - accuracy: 0.9804 - loss: 0.0507 - val_accuracy: 0.9806 - val_loss: 0.0498\n",
      "Epoch 7/10\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 759ms/step - accuracy: 0.9814 - loss: 0.0475 - val_accuracy: 0.9815 - val_loss: 0.0475\n",
      "Epoch 8/10\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 766ms/step - accuracy: 0.9821 - loss: 0.0456 - val_accuracy: 0.9822 - val_loss: 0.0452\n",
      "Epoch 9/10\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 784ms/step - accuracy: 0.9824 - loss: 0.0444 - val_accuracy: 0.9827 - val_loss: 0.0434\n",
      "Epoch 10/10\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 770ms/step - accuracy: 0.9831 - loss: 0.0422 - val_accuracy: 0.9833 - val_loss: 0.0421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2d2fac5d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create input and target sequences from the encoded event log\n",
    "input_sequences = [[event['concept:name']\n",
    "                    for event in trace[:-1]] for trace in event_log]\n",
    "target_sequences = [[event['concept:name']\n",
    "                     for event in trace[1:]] for trace in event_log]\n",
    "\n",
    "# Pad sequences and prepare data for training\n",
    "max_sequence_length = max([len(seq) for seq in input_sequences])\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='post')\n",
    "\n",
    "target_sequences = pad_sequences(target_sequences, maxlen=max_sequence_length, padding='post')\n",
    "\n",
    "target_sequences = to_categorical(target_sequences, num_classes=len(activity_encoder.classes_))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "input_train, input_test, target_train, target_test = train_test_split(input_sequences, target_sequences, test_size=0.2)\n",
    "\n",
    "# Assuming build_seq2seq_model is defined and ready\n",
    "model = build_seq2seq_model(input_vocab_size=len(activity_encoder.classes_), output_vocab_size=len(activity_encoder.classes_))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit([input_train, input_train], target_train,batch_size=64, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Predictions and Timestamps to new files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 221ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict([input_test, input_test])\n",
    "predicted_sequences = np.argmax(predictions, axis=-1)\n",
    "\n",
    "# Inverse transform to get the activity names back\n",
    "predicted_activities = [activity_encoder.inverse_transform(seq) for seq in predicted_sequences]\n",
    "\n",
    "# Generate timestamps for each predicted activity based on the average duration\n",
    "predicted_timestamps = []\n",
    "for activities in predicted_activities:\n",
    "    timestamps = [dataframe['time:timestamp'].min() + timedelta(minutes=i*average_duration) for i in range(len(activities))]\n",
    "    \n",
    "    predicted_timestamps.append([ts.strftime('%Y-%m-%d %H:%M:%S') for ts in timestamps])\n",
    "\n",
    "# Prepare and save the DataFrame\n",
    "test_case_ids = [trace.attributes['concept:name'] for trace in event_log][:len(predicted_activities)] \n",
    "\n",
    "df_predictions = pd.DataFrame({\n",
    "    'case:concept:name': test_case_ids,\n",
    "    'predicted_trace': ['; '.join(activities) for activities in predicted_activities],\n",
    "    'predicted_timestamps': ['; '.join(timestamps) for timestamps in predicted_timestamps]\n",
    "})\n",
    "df_predictions.to_csv(f'{data_path}/Seq2Seq_predictions_{chosed_dataset}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
